{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_MNIST",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KoMurase/interest/blob/master/Fashion_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IVAZ4Wp1E1b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.datasets import FashionMNIST \n",
        "from torchvision import transforms\n",
        "\n",
        "from torch.utils.data import DataLoader,Dataset,TensorDataset\n",
        "import tqdm\n",
        "from torch import nn,optim\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9A9JGN5eTE1",
        "colab_type": "code",
        "outputId": "efc86921-461e-4da6-ade6-c6e70022dfa6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2018 NVIDIA Corporation\n",
            "Built on Sat_Aug_25_21:08:01_CDT_2018\n",
            "Cuda compilation tools, release 10.0, V10.0.130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9QlrN6-eXcc",
        "colab_type": "code",
        "outputId": "91df10c5-339b-44b8-d765-64f85db532e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-cnoaty4p\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-cnoaty4p\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4307 sha256=16fdf98ee799079b0546a7ff6a71eb29b28d1fa3280587e440bf909e29816dc7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c22o_hmm/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.2\n",
            "created output directory at /content/src\n",
            "Out bin /content/result.out\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfIO36Rsr0ca",
        "colab_type": "code",
        "outputId": "f1c80700-5209-49e9-d716-5bcb4d3d6d86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "source": [
        "!git clone https://github.com/NVIDIA/cuda-samples/\n",
        "!cp cuda-samples/Common/* /usr/local/include"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cuda-samples'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (66/66), done.\u001b[K\n",
            "remote: Total 1090 (delta 70), reused 120 (delta 67), pack-reused 952\u001b[K\n",
            "Receiving objects: 100% (1090/1090), 25.39 MiB | 7.98 MiB/s, done.\n",
            "Resolving deltas: 100% (853/853), done.\n",
            "cp: -r not specified; omitting directory 'cuda-samples/Common/FreeImage'\n",
            "cp: -r not specified; omitting directory 'cuda-samples/Common/UtilNPP'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1OiI-8T1XWd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "60d616b1-6d7d-4bf1-fa8c-38a1e092ae98"
      },
      "source": [
        "fashion_mnist_train = FashionMNIST('../FashionMNIST',\n",
        "                                  train=True,download=True,transform=transforms.ToTensor())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:04, 5670748.78it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 34732.86it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:02, 1653852.80it/s]                            \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "8192it [00:00, 13928.59it/s]            "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q6XYZTy1zpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist_test = FashionMNIST('../FashionMNIST',\n",
        "                                  train=False,download=True,transform=transforms.ToTensor())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gYNE222Jwv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "train_loader = DataLoader(fashion_mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(fashion_mnist_test, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h2F8cj73OdK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(N,C,H,W)形式のTensorを(N,C*H*W)に引き延ばす層\n",
        "\n",
        "class FlattenLayer(nn.Module):\n",
        "  def forward(self,x):\n",
        "    sizes = x.size()\n",
        "    return x.view(sizes[0],-1)\n",
        "\n",
        "  #5X5のカーネルを使用し最初に32個,次に64個のチャネルを作成する\n",
        "  #BatchNorm2dは画像形式用のDropout \n",
        "  #最後にFlattenLayerを挟む\n",
        "conv_net = nn.Sequential(\n",
        "    nn.Conv2d(1,32,5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.Dropout2d(0.25),\n",
        "    nn.Conv2d(32,64,5),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(64),\n",
        "    FlattenLayer()\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpjYMZB9Yddw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input = torch.ones(1,1,28,28)\n",
        "conv_output_size = conv_net(test_input).size()[-1]\n",
        "\n",
        "#2層のMLP\n",
        "mlp = nn.Sequential(\n",
        "  nn.Linear(conv_output_size, 200),\n",
        "  nn.ReLU(),\n",
        "  nn.BatchNorm1d(200),\n",
        "  nn.Linear(200,10)\n",
        ")\n",
        "#最終的なCNN\n",
        "net = nn.Sequential(\n",
        "  conv_net,\n",
        "  mlp\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbkVXnrTc7-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#評価のヘルパー関数\n",
        "def eval_net(net, data_loader,device='cpu'):\n",
        "  #DropoutやBatchNormを無効化\n",
        "  net.eval()\n",
        "  ys = []\n",
        "  ypreds = []\n",
        "  \n",
        "  for x,y in data_loader: \n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      _,y_pred = net(x).max(1)\n",
        "    ys.append(y)\n",
        "    ypreds.append(y_pred)\n",
        "    \n",
        "    ys = torch.cat(ys)\n",
        "    ypreds = torch.cat(ypreds)\n",
        "    \n",
        "    acc = (ys == ypreds).float().sum() / len(ys)\n",
        "    return acc.item()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWIRaupz5-Xr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_net(net,train_loader,test_loader,optimizer_cls=optim.Adam,\n",
        "             loss_fn=nn.CrossEntropyLoss(),n_iter=10,device='cuda:0'):\n",
        "  train_losses = []\n",
        "  train_acc = []\n",
        "  val_acc = []\n",
        "  optimizer = optimizer_cls(net.parameters())\n",
        "  \n",
        "  for epoch in range(n_iter):\n",
        "    running_loss = 0.0\n",
        "    \n",
        "    #ネットワークを訓練モードにする\n",
        "    net.train() \n",
        "    n = 0\n",
        "    n_acc = 0\n",
        "    \n",
        "    for i , (xx,yy) in tqdm.tqdm(enumerate(train_loader),total=len(train_loader)):\n",
        "      xx = xx.to(device)\n",
        "      yy = yy.to(device)\n",
        "      h = net(xx)\n",
        "      loss = loss_fn(h,yy)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item() \n",
        "      n += len(xx)\n",
        "      \n",
        "      _,y_pred = h.max(1)\n",
        "      n_acc += (yy == y_pred).float().sum().item()\n",
        "  \n",
        "  train_losses.append(running_loss / i)\n",
        "  \n",
        "  #訓練データの予測精度\n",
        "  train_acc.append(n_acc / n)\n",
        "  val_acc.append(eval_net(net,test_loader,device))\n",
        "  #このエポックでの結果を表示\n",
        "  print(epoch,train_losses[-1],train_acc[-1],val_acc[-1],flush=True)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp0txpl2lZaB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "8c6434f5-2a06-45b8-9e0d-dbc7f27c937d"
      },
      "source": [
        "#ネットワークの全パラメータをGPUに転送\n",
        "net.to('cuda:0')\n",
        "\n",
        "#訓練の実行\n",
        "train_net(net,train_loader,test_loader,n_iter=20,device='cuda:0')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 469/469 [00:12<00:00, 36.88it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 36.72it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.11it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.19it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.13it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 36.15it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 36.86it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.07it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.21it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.23it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.08it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.52it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.55it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.49it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.51it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.53it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.37it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.61it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.65it/s]\n",
            "100%|██████████| 469/469 [00:12<00:00, 37.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "19 0.066478239145512 0.9757666666666667 0.8984375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sgfs34girsXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}